const fs = require("fs");
const path = require("path");
const { getQuery, runQuery } = require("./database/db");

(async () => {
  try {
    const filePath = path.join(__dirname, "data", "grammar.json");// ƒë∆∞·ªùng d·∫´n 

    if (!fs.existsSync(filePath)) {
      console.error("‚ùå Kh√¥ng t√¨m th·∫•y file grammar.json trong th∆∞ m·ª•c g·ªëc!");
      process.exit(1);
    }

    const rawData = fs.readFileSync(filePath, "utf8");
    const data = JSON.parse(rawData);

    // Chu·∫©n b·ªã b·∫£ng
    await runQuery(`
      CREATE TABLE IF NOT EXISTS grammar (
        id INT AUTO_INCREMENT PRIMARY KEY,
        level VARCHAR(5) NOT NULL,
        structure VARCHAR(255) NOT NULL,
        meaning VARCHAR(255) NOT NULL,
        example TEXT,
        translation TEXT
      ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
    `);

    // Import d·ªØ li·ªáu
    for (const level of Object.keys(data)) {
      const grammars = data[level];
      console.log(`üü° Importing ${grammars.length} records for level ${level}...`);

      for (const item of grammars) {
        await runQuery(
          `INSERT INTO grammar (level, structure, meaning, example, translation)
           VALUES (?, ?, ?, ?, ?)`,
          [
            level.trim().toUpperCase(),
            item.structure || "",
            item.meaning || "",
            item.example || "",
            item.translation || "",
          ]
        );
      }

      console.log(`‚úÖ Ho√†n t·∫•t ${grammars.length} m·∫´u ng·ªØ ph√°p ${level}`);
    }

    console.log("üéâ T·∫•t c·∫£ d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c import th√†nh c√¥ng!");
    process.exit(0);
  } catch (err) {
    console.error("‚ùå L·ªói khi import d·ªØ li·ªáu:", err);
    process.exit(1);
  }
})();
